# Music Recommendation System Comparative Study

## Introduction

In the realm of digital music streaming, providing personalized song recommendations is a critical component of user engagement and satisfaction. For our final project in the Spring 2023 DS-GA 1004 course, our group decided to delve into the fascinating world of recommender systems, specifically focusing on music recommendation. Our project is a comparative study of multiple recommendation algorithms, assessing their performance and efficiency in terms of predictive accuracy and computational time. The algorithms we've explored include the Popularity-Based Model, the Alternating Least Squares (ALS) Model, LightFM, and a Fast Search approach using the ANNOY library. Through this project, we aim to understand the strengths, weaknesses, and appropriate use-cases for each model, with the ultimate goal of improving music recommendation quality and efficiency.

## Data Preprocessing

Our data preprocessing step was implemented using PySpark due to the large size of our dataset. The dataset was obtained from the ListenBrainz dataset, which consists of implicit feedback from music listening behavior, spanning over 6,800 distinct users and more than 50 million song interactions.

The preprocessing included data filtering, feature extraction, and partitioning of the data into training, validation, and test sets.

- **Data Loading:** We loaded the training data from 'interactions_train_small.parquet' and the test data from 'interactions_test.parquet'. These files contained interactions between users and tracks.

- **Filtering:** We filtered out users who had less than 50 interactions with tracks to ensure the robustness of our recommender system and mitigate the cold start problem.

- **Track ID:** We assigned a unique numeric 'track_id' to each unique 'recording_msid' to meet the requirements of the ALS model.

- **Data Partitioning:** We split the filtered data into training and validation sets using stratified sampling by 'user_id' to mitigate the cold start problem.

- **Data Saving:** The preprocessed training, validation, and test sets were saved back to parquet files. Additionally, validation and test data were further reduced to 'user_id' and a set of track_ids they have interacted with for model performance evaluation.

## Popularity-Based Model

### Baseline Implementation

We implemented a baseline popularity model that recommends the most popular songs to all users based on the number of unique listeners. The popularity measure is calculated as the ratio of distinct listeners for a track over the total number of plays for that track plus a hyperparameter beta.

### Baseline Performance

The baseline popularity model's performance was evaluated on the training and validation sets using the Mean Average Precision at K (MAP@K) metric. The best value of beta was determined to be 200,000, which yielded a validation MAP@K of 0.000985. The popularity baseline MAP@K at 100 on the test set was 0.000982.

## ALS Model

### ALS Implementation

The ALS model, a matrix factorization algorithm, was implemented using PySpark's ML library. We used the implicit preferences variant of ALS due to the implicit feedback nature of our dataset. The model was initialized with hyperparameters such as rank, regularization parameter, and alpha.

### ALS Performance

The ALS model's performance was evaluated by tuning the hyperparameters and measuring the MAP@K on the validation set. The optimal hyperparameters were determined to be a rank of 50, lambda of 0.1, and alpha of 0.5, resulting in a validation MAP@K of 0.041053. The test MAP@K using these hyperparameters was 0.032762. The ALS model demonstrated high-quality recommendations and computational efficiency compared to the baseline model.

## Extension 1: LightFM

### LightFM Implementation

The LightFM model, a hybrid matrix factorization algorithm, was implemented alongside the ALS model. We used Python Pandas for preprocessing and transformed the data into a sparse matrix. LightFM was trained using the 'warp' loss function suitable for implicit feedback data.

### LightFM Performance

Due to computational limitations, LightFM was trained and evaluated on only 1% of the data. It showed poor scalability and predictive performance compared to the Spark ALS model. The MAP@K score for LightFM was 0.001214, indicating poor predictive performance.

## Extension 2: Fast Search with ANNOY

### Fast Search with ANNOY Implementation

The Fast Search extension utilized the ANNOY library for efficient approximate nearest neighbor search. The implementation involved creating an index from the item factors generated by the basic ALS model using ANNOY. Recommendations were generated using the ANNOY index.

### Fast Search with ANNOY Performance

Fast Search with ANNOY demonstrated high computational efficiency, with the total time taken for index creation and recommendation generation being approximately 0.48 seconds and 0.14 seconds, respectively. The MAP@K score for ANNOY was 0.048, indicating superior predictive performance compared to the Spark ALS model.

## Conclusion

In conclusion, our comparative study of recommender systems revealed the strengths and limitations of different algorithms. The ALS model exhibited high-quality recommendations and computational efficiency, making it a suitable choice for large-scale datasets. LightFM struggled with scalability and predictive performance. The Fast Search approach with ANNOY demonstrated superior computational efficiency and predictive performance, offering a compelling solution for scenarios requiring quick recommendation generation and high-quality results.
